"""
Module de pr√©paration des donn√©es pour le GNN spatial.
G√®re la normalisation, le filtrage et la construction du graphe K-NN.
"""

import numpy as np
import scanpy as sc
import torch
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from torch_geometric.data import Data
from scipy.sparse import issparse


def preprocess_adata(adata, normalize_genes=True,
                     min_genes_per_cell=200, min_cells_per_gene=3):
    """
    Filtre et normalise les donn√©es d'expression.

    Args:
        adata: AnnData object contenant les donn√©es Xenium
        normalize_genes: Si True, applique normalize_total + log1p aux g√®nes
        normalize_proteins: Ignor√© (pour compatibilit√©)
        min_genes_per_cell: Nombre minimum de g√®nes d√©tect√©s par cellule
        min_cells_per_gene: Nombre minimum de cellules exprimant un g√®ne

    Returns:
        adata_processed: AnnData avec seulement Gene Expression (RNA)
    """
    print(f"üìä Donn√©es initiales: {adata.n_obs} cellules, {adata.n_vars} features")

    # Cr√©er le masque pour ne garder que les g√®nes
    gene_mask = adata.var["feature_types"] == "Gene Expression"

    # Filtrer pour ne garder QUE les g√®nes (pas de prot√©ines)
    adata_filtered = adata[:, gene_mask].copy()

    print(f"Apr√®s filtrage des prot√©ines: {adata_filtered.n_obs} cellules, {adata_filtered.n_vars} g√®nes")

    # Convertir en dense d√®s le d√©but pour simplifier
    if issparse(adata_filtered.X):
        adata_filtered.X = adata_filtered.X.toarray()

    # üîç FILTRAGE DE QUALIT√â
    print(f"\nüîç Filtrage de qualit√©...")
    print(f"   ‚Ä¢ Seuil cellules: min {min_genes_per_cell} g√®nes d√©tect√©s")
    print(f"   ‚Ä¢ Seuil g√®nes: min {min_cells_per_gene} cellules")

    # Filtrer les cellules avec peu de g√®nes d√©tect√©s
    n_genes_per_cell = (adata_filtered.X > 0).sum(axis=1)
    cell_mask = n_genes_per_cell >= min_genes_per_cell
    adata_filtered = adata_filtered[cell_mask, :].copy()
    print(f"   ‚úì Cellules apr√®s filtrage: {adata_filtered.n_obs} ({cell_mask.sum()}/{len(cell_mask)})")

    # Filtrer les g√®nes exprim√©s dans peu de cellules
    n_cells_per_gene = (adata_filtered.X > 0).sum(axis=0)
    gene_filter_mask = n_cells_per_gene >= min_cells_per_gene
    adata_filtered = adata_filtered[:, gene_filter_mask].copy()
    print(f"   ‚úì G√®nes apr√®s filtrage: {adata_filtered.n_vars} ({gene_filter_mask.sum()}/{len(gene_filter_mask)})")

    print(f"\nüìä Donn√©es apr√®s filtrage de qualit√©:")
    print(f"   ‚Ä¢ Cellules: {adata_filtered.n_obs}")
    print(f"   ‚Ä¢ G√®nes (RNA): {adata_filtered.n_vars}")
    print(f"   ‚Ä¢ Total features: {adata_filtered.n_vars}")

    # Normalisation des g√®nes
    if normalize_genes:
        # Normalisation scanpy (total counts + log1p)
        sc.pp.normalize_total(adata_filtered, target_sum=1e4)
        sc.pp.log1p(adata_filtered)
        print("‚úì G√®nes normalis√©s (normalize_total + log1p)")

    # Pas de normalisation de prot√©ines puisqu'elles sont exclues

    return adata_filtered


def build_knn_graph(features, spatial_coords, k=29, metric='cosine'):
    """
    Construit un graphe K-NN bas√© sur la similarit√© d'expression.

    Args:
        features: Matrice de features normalis√©es (n_cells, n_features)
        spatial_coords: Coordonn√©es spatiales r√©elles (n_cells, 2) pour les labels
        k: Nombre de voisins
        metric: 'cosine' ou 'euclidean'

    Returns:
        data: Objet torch_geometric.data.Data avec le graphe et les labels
        coords_scaler: Scaler pour d√©normaliser les coordonn√©es
    """
    print(f"\nConstruction du graphe K-NN (k={k}, metric={metric})...")

    # Convertir features en numpy si n√©cessaire
    if issparse(features):
        features_array = features.toarray()
    else:
        features_array = np.array(features)

    # K-NN bas√© sur similarit√© d'expression (pas les coordonn√©es!)
    nbrs = NearestNeighbors(n_neighbors=k+1, metric=metric, n_jobs=-1)
    nbrs.fit(features_array)

    # Trouver les voisins (k+1 car le premier voisin est la cellule elle-m√™me)
    distances, indices = nbrs.kneighbors(features_array)

    # Construire la liste d'ar√™tes (exclure self-loops)
    edge_list = []
    for i in range(len(indices)):
        for j in range(1, k+1):  # Commencer √† 1 pour √©viter self-loop
            edge_list.append([i, indices[i, j]])

    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()

    print(f"‚úì Graphe cr√©√©: {features_array.shape[0]} n≈ìuds, {edge_index.shape[1]} ar√™tes")

    # Normaliser les coordonn√©es spatiales (z-score)
    coords_scaler = StandardScaler()
    spatial_coords_normalized = coords_scaler.fit_transform(spatial_coords)

    # Cr√©er l'objet Data PyTorch Geometric
    data = Data(
        x=torch.tensor(features_array, dtype=torch.float32),
        edge_index=edge_index,
        y=torch.tensor(spatial_coords_normalized, dtype=torch.float32),
        pos_original=torch.tensor(spatial_coords, dtype=torch.float32)
    )

    print(f"‚úì Features shape: {data.x.shape}")
    print(f"‚úì Coordonn√©es normalis√©es: mean={spatial_coords_normalized.mean():.3f}, std={spatial_coords_normalized.std():.3f}")

    return data, coords_scaler


def create_train_val_test_masks(n_nodes, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):
    """
    Cr√©e des masques pour split train/val/test.

    Args:
        n_nodes: Nombre total de n≈ìuds (cellules)
        train_ratio: Proportion de donn√©es d'entra√Ænement
        val_ratio: Proportion de donn√©es de validation
        test_ratio: Proportion de donn√©es de test
        seed: Seed pour reproductibilit√©

    Returns:
        train_mask, val_mask, test_mask: Tenseurs bool√©ens
    """
    np.random.seed(seed)
    indices = np.random.permutation(n_nodes)

    train_size = int(train_ratio * n_nodes)
    val_size = int(val_ratio * n_nodes)

    train_indices = indices[:train_size]
    val_indices = indices[train_size:train_size + val_size]
    test_indices = indices[train_size + val_size:]

    train_mask = torch.zeros(n_nodes, dtype=torch.bool)
    val_mask = torch.zeros(n_nodes, dtype=torch.bool)
    test_mask = torch.zeros(n_nodes, dtype=torch.bool)

    train_mask[train_indices] = True
    val_mask[val_indices] = True
    test_mask[test_indices] = True

    print(f"\n‚úì Split: Train={train_mask.sum()}, Val={val_mask.sum()}, Test={test_mask.sum()}")

    return train_mask, val_mask, test_mask